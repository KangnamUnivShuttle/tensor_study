{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_set = np.loadtxt(\"https://raw.githubusercontent.com/gilbutITbook/006958/master/deeplearning/dataset/ThoraricSurgery.csv\", delimiter=\",\")\n",
    "Data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data_set[:, 0:17] # y: 0 ~ n, x: 0 ~ 16\n",
    "Y = Data_set[:, 17] # y: 0 ~ n, x: 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력값 17 개를 받을 것이고 이것이 x1 ~ x17 로 시작함\n",
    "\n",
    "그 바로 다음에 n1 ~ n30 의 30 개의 노드가 존재함\n",
    "\n",
    "\n",
    "여기 까지가 은닉층\n",
    "-----------------------\n",
    "\n",
    "위의 노드 30 개가 하나의 결과로 모이도록\n",
    "\n",
    "노드 1개인 출력층을 만들어 냄\n",
    "\n",
    "여기 까지가 출력층\n",
    "-----------------------\n",
    "\n",
    "activation 은 각 노드 별 활성화 함수로 사용할 것을 선택하며 이 결과가 출력 층으로 전달 됨\n",
    "\n",
    "\n",
    "## 최종 구조는?\n",
    "\n",
    "```\n",
    "x1 ~ x17 ----> (n1 ~ n30 가중 합) -> relu ----> sub_y1 ~ sub_y30 ----> (N0 가중 합) -> sigmoid ----> y result\n",
    "          W(1) |-----------------------|                        W(2) |--------------------|\n",
    "                      LAYER 1                                              LAYER 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu')) # 30 개의 노드, 17 개의 입력, relu 함수 사용 x 가 음수면 y 가 0 이다가 x 가 양수면 y 도 양수 <-- 가 하나의 레이어\n",
    "model.add(Dense(1, activation='sigmoid')) # 1 개의 노드, sigmoid 함수 사용 0 혹은 1 값이 결과로 나올 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 1s 1ms/sample - loss: 0.1514 - accuracy: 0.8447\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 162us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 153us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 151us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 172us/sample - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 167us/sample - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 154us/sample - loss: 0.1478 - accuracy: 0.8468\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 147us/sample - loss: 0.1478 - accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 152us/sample - loss: 0.1446 - accuracy: 0.8447\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 148us/sample - loss: 0.1465 - accuracy: 0.8511\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 152us/sample - loss: 0.1463 - accuracy: 0.8468\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 160us/sample - loss: 0.1443 - accuracy: 0.8489\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1436 - accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 161us/sample - loss: 0.1450 - accuracy: 0.8532\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 148us/sample - loss: 0.1442 - accuracy: 0.8511\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1433 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 162us/sample - loss: 0.1477 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 158us/sample - loss: 0.1483 - accuracy: 0.8511\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1472 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 170us/sample - loss: 0.1473 - accuracy: 0.8511\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 175us/sample - loss: 0.1453 - accuracy: 0.8468\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 168us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 163us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 165us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 158us/sample - loss: 0.1484 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 160us/sample - loss: 0.1433 - accuracy: 0.8468\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 149us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 160us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 153us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 151us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 152us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 181us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 165us/sample - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 149us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 160us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1472 - accuracy: 0.8489\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 160us/sample - loss: 0.1446 - accuracy: 0.8532\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1441 - accuracy: 0.8532\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 165us/sample - loss: 0.1457 - accuracy: 0.8468\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 153us/sample - loss: 0.1442 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1457 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1407 - accuracy: 0.8489\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 161us/sample - loss: 0.1485 - accuracy: 0.8468\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 154us/sample - loss: 0.1456 - accuracy: 0.8511\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 153us/sample - loss: 0.1409 - accuracy: 0.8532\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 149us/sample - loss: 0.1423 - accuracy: 0.8553\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 156us/sample - loss: 0.1415 - accuracy: 0.8489\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1417 - accuracy: 0.8468\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 151us/sample - loss: 0.1374 - accuracy: 0.8553\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 159us/sample - loss: 0.1427 - accuracy: 0.8468\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 158us/sample - loss: 0.1466 - accuracy: 0.8447\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1437 - accuracy: 0.8319\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1483 - accuracy: 0.8404\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 164us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 75us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 164us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 149us/sample - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 160us/sample - loss: 0.1482 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 158us/sample - loss: 0.1468 - accuracy: 0.8468\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 162us/sample - loss: 0.1442 - accuracy: 0.8532\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 153us/sample - loss: 0.1457 - accuracy: 0.8426\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1453 - accuracy: 0.8532\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 153us/sample - loss: 0.1412 - accuracy: 0.8553\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 167us/sample - loss: 0.1416 - accuracy: 0.8553\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 163us/sample - loss: 0.1388 - accuracy: 0.8574\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 165us/sample - loss: 0.1407 - accuracy: 0.8596\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1432 - accuracy: 0.8489\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 163us/sample - loss: 0.1421 - accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1435 - accuracy: 0.8532\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 154us/sample - loss: 0.1444 - accuracy: 0.8468\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 155us/sample - loss: 0.1410 - accuracy: 0.8553\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 156us/sample - loss: 0.1370 - accuracy: 0.8596\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 156us/sample - loss: 0.1374 - accuracy: 0.8553\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1364 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 156us/sample - loss: 0.1327 - accuracy: 0.8596\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 161us/sample - loss: 0.1333 - accuracy: 0.8596\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 151us/sample - loss: 0.1349 - accuracy: 0.8574\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1342 - accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 150us/sample - loss: 0.1310 - accuracy: 0.8638\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 159us/sample - loss: 0.1318 - accuracy: 0.8617 - loss: 0.1163 - accuracy: 0.88\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1336 - accuracy: 0.8596\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1353 - accuracy: 0.8532\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 163us/sample - loss: 0.1302 - accuracy: 0.8660\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 156us/sample - loss: 0.1318 - accuracy: 0.8681\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 154us/sample - loss: 0.1366 - accuracy: 0.8574\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 159us/sample - loss: 0.1326 - accuracy: 0.8638\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 157us/sample - loss: 0.1328 - accuracy: 0.8596\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 165us/sample - loss: 0.1330 - accuracy: 0.8574\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 158us/sample - loss: 0.1315 - accuracy: 0.8681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffaa317c0b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy']) # MSE 로 오차함수 지정, adam 으로 최적화, 과적합 방지\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
