{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.datasets import mnist, reuters\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '두개랑', '탕수육', '작은걸로', '갖다주세요']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '짜장면 두개랑 탕수육 작은걸로 갖다주세요'\n",
    "text_to_word_sequence(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words\n",
    "\n",
    "- 단어별로 나누어서 가방에 넣어둔 뒤 얼마나 많은 빈도수로 쓰였는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    '2020년까지 많은 데이터가 구축되었다.',\n",
    "    '그 중에서 비교적 대부분의 사람들이 접근할 수 있는 오픈 데이터를 정리하였다.',\n",
    "    '구할 수 있는 모든 데이터를 쏟아 부어서 end to end로 모델을 만들어 보겠다는 포부를 가진 분들의 진입을 쉽게하기 위한 목적이고, 정교한 데이터 구축을 위해서는 이후에 어떠한 데이터가 필요한지를 살펴보기 위한 과정이다.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('2020년까지', 1),\n",
       "             ('많은', 1),\n",
       "             ('데이터가', 2),\n",
       "             ('구축되었다', 1),\n",
       "             ('그', 1),\n",
       "             ('중에서', 1),\n",
       "             ('비교적', 1),\n",
       "             ('대부분의', 1),\n",
       "             ('사람들이', 1),\n",
       "             ('접근할', 1),\n",
       "             ('수', 2),\n",
       "             ('있는', 2),\n",
       "             ('오픈', 1),\n",
       "             ('데이터를', 2),\n",
       "             ('정리하였다', 1),\n",
       "             ('구할', 1),\n",
       "             ('모든', 1),\n",
       "             ('쏟아', 1),\n",
       "             ('부어서', 1),\n",
       "             ('end', 1),\n",
       "             ('to', 1),\n",
       "             ('end로', 1),\n",
       "             ('모델을', 1),\n",
       "             ('만들어', 1),\n",
       "             ('보겠다는', 1),\n",
       "             ('포부를', 1),\n",
       "             ('가진', 1),\n",
       "             ('분들의', 1),\n",
       "             ('진입을', 1),\n",
       "             ('쉽게하기', 1),\n",
       "             ('위한', 2),\n",
       "             ('목적이고', 1),\n",
       "             ('정교한', 1),\n",
       "             ('데이터', 1),\n",
       "             ('구축을', 1),\n",
       "             ('위해서는', 1),\n",
       "             ('이후에', 1),\n",
       "             ('어떠한', 1),\n",
       "             ('필요한지를', 1),\n",
       "             ('살펴보기', 1),\n",
       "             ('과정이다', 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "token.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "document_count 는 총 몇 개의 문장인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'데이터가': 2,\n",
       "             '많은': 1,\n",
       "             '2020년까지': 1,\n",
       "             '구축되었다': 1,\n",
       "             '대부분의': 1,\n",
       "             '중에서': 1,\n",
       "             '오픈': 1,\n",
       "             '사람들이': 1,\n",
       "             '데이터를': 2,\n",
       "             '접근할': 1,\n",
       "             '있는': 2,\n",
       "             '정리하였다': 1,\n",
       "             '그': 1,\n",
       "             '비교적': 1,\n",
       "             '수': 2,\n",
       "             '데이터': 1,\n",
       "             '가진': 1,\n",
       "             'end로': 1,\n",
       "             '보겠다는': 1,\n",
       "             '모델을': 1,\n",
       "             '포부를': 1,\n",
       "             '분들의': 1,\n",
       "             '위한': 1,\n",
       "             '필요한지를': 1,\n",
       "             '정교한': 1,\n",
       "             '만들어': 1,\n",
       "             '살펴보기': 1,\n",
       "             '진입을': 1,\n",
       "             '이후에': 1,\n",
       "             '위해서는': 1,\n",
       "             '구할': 1,\n",
       "             '구축을': 1,\n",
       "             '목적이고': 1,\n",
       "             'end': 1,\n",
       "             '모든': 1,\n",
       "             '쉽게하기': 1,\n",
       "             '과정이다': 1,\n",
       "             '쏟아': 1,\n",
       "             'to': 1,\n",
       "             '부어서': 1,\n",
       "             '어떠한': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.word_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어들이 몇 개의 문장에서 나오는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    '2020년까지 많은 데이터가 구축되었다. 그 중에서 비교적 대부분의 사람들이 접근할 수 있는 오픈 데이터를 정리하였다. 구할 수 있는 모든 데이터를 쏟아 부어서 end to end로 모델을 만들어 보겠다는 포부를 가진 분들의 진입을 쉽게하기 위한 목적이고, 정교한 데이터 구축을 위해서는 이후에 어떠한 데이터가 필요한지를 살펴보기 위한 과정이다.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('2020년까지', 1),\n",
       "             ('많은', 1),\n",
       "             ('데이터가', 2),\n",
       "             ('구축되었다', 1),\n",
       "             ('그', 1),\n",
       "             ('중에서', 1),\n",
       "             ('비교적', 1),\n",
       "             ('대부분의', 1),\n",
       "             ('사람들이', 1),\n",
       "             ('접근할', 1),\n",
       "             ('수', 2),\n",
       "             ('있는', 2),\n",
       "             ('오픈', 1),\n",
       "             ('데이터를', 2),\n",
       "             ('정리하였다', 1),\n",
       "             ('구할', 1),\n",
       "             ('모든', 1),\n",
       "             ('쏟아', 1),\n",
       "             ('부어서', 1),\n",
       "             ('end', 1),\n",
       "             ('to', 1),\n",
       "             ('end로', 1),\n",
       "             ('모델을', 1),\n",
       "             ('만들어', 1),\n",
       "             ('보겠다는', 1),\n",
       "             ('포부를', 1),\n",
       "             ('가진', 1),\n",
       "             ('분들의', 1),\n",
       "             ('진입을', 1),\n",
       "             ('쉽게하기', 1),\n",
       "             ('위한', 2),\n",
       "             ('목적이고', 1),\n",
       "             ('정교한', 1),\n",
       "             ('데이터', 1),\n",
       "             ('구축을', 1),\n",
       "             ('위해서는', 1),\n",
       "             ('이후에', 1),\n",
       "             ('어떠한', 1),\n",
       "             ('필요한지를', 1),\n",
       "             ('살펴보기', 1),\n",
       "             ('과정이다', 1)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "token.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'데이터': 1,\n",
       "             '중에서': 1,\n",
       "             '구축되었다': 1,\n",
       "             'end로': 1,\n",
       "             '보겠다는': 1,\n",
       "             '가진': 1,\n",
       "             '있는': 1,\n",
       "             '모델을': 1,\n",
       "             '수': 1,\n",
       "             '포부를': 1,\n",
       "             '분들의': 1,\n",
       "             '위한': 1,\n",
       "             '필요한지를': 1,\n",
       "             '정교한': 1,\n",
       "             '정리하였다': 1,\n",
       "             '만들어': 1,\n",
       "             '데이터를': 1,\n",
       "             '살펴보기': 1,\n",
       "             '진입을': 1,\n",
       "             '이후에': 1,\n",
       "             '위해서는': 1,\n",
       "             '대부분의': 1,\n",
       "             '많은': 1,\n",
       "             '2020년까지': 1,\n",
       "             '구할': 1,\n",
       "             '구축을': 1,\n",
       "             '접근할': 1,\n",
       "             '목적이고': 1,\n",
       "             '그': 1,\n",
       "             '비교적': 1,\n",
       "             'end': 1,\n",
       "             '오픈': 1,\n",
       "             '모든': 1,\n",
       "             '사람들이': 1,\n",
       "             '쉽게하기': 1,\n",
       "             '과정이다': 1,\n",
       "             '쏟아': 1,\n",
       "             'to': 1,\n",
       "             '데이터가': 1,\n",
       "             '부어서': 1,\n",
       "             '어떠한': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.word_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열을 일부러 합쳐서 하나의 문자열로 바꾸었지만 . 로 문장 끝은 알려준 상태\n",
    "\n",
    "하지만 각 문자열 갯수를 문장으로 인식하는 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'데이터가': 1,\n",
       " '수': 2,\n",
       " '있는': 3,\n",
       " '데이터를': 4,\n",
       " '위한': 5,\n",
       " '2020년까지': 6,\n",
       " '많은': 7,\n",
       " '구축되었다': 8,\n",
       " '그': 9,\n",
       " '중에서': 10,\n",
       " '비교적': 11,\n",
       " '대부분의': 12,\n",
       " '사람들이': 13,\n",
       " '접근할': 14,\n",
       " '오픈': 15,\n",
       " '정리하였다': 16,\n",
       " '구할': 17,\n",
       " '모든': 18,\n",
       " '쏟아': 19,\n",
       " '부어서': 20,\n",
       " 'end': 21,\n",
       " 'to': 22,\n",
       " 'end로': 23,\n",
       " '모델을': 24,\n",
       " '만들어': 25,\n",
       " '보겠다는': 26,\n",
       " '포부를': 27,\n",
       " '가진': 28,\n",
       " '분들의': 29,\n",
       " '진입을': 30,\n",
       " '쉽게하기': 31,\n",
       " '목적이고': 32,\n",
       " '정교한': 33,\n",
       " '데이터': 34,\n",
       " '구축을': 35,\n",
       " '위해서는': 36,\n",
       " '이후에': 37,\n",
       " '어떠한': 38,\n",
       " '필요한지를': 39,\n",
       " '살펴보기': 40,\n",
       " '과정이다': 41}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 데이터가 존재하는 순서 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word one-hot-coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '두개랑', '탕수육', '작은걸로', '갖다주세요']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '짜장면 두개랑 탕수육 작은걸로 갖다주세요'\n",
    "text_to_word_sequence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'짜장면': 1, '두개랑': 2, '탕수육': 3, '작은걸로': 4, '갖다주세요': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts([text])\n",
    "token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.texts_to_sequences([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_size = len(token.word_index) + 1 # 배열이 0부터 시작하니 일부러 1번지 부터 시작하기 위해 사이즈를 늘림\n",
    "to_categorical(token.texts_to_sequences([text]), num_classes=word_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "\n",
    "- 위와 같이 단어들을 one-hot-coding 하면 벡터 길이가 n 개로 너무 길어짐\n",
    "- n 길이의 벡터를 정해진 사이즈로 줄임\n",
    "- 어떤 단어가 다른 단어와 유사하다 라는 정보를 이용해 벡터 값을 고려한 one-hot-coding\n",
    "\n",
    "ex)\n",
    "\n",
    "행복함 은 좋음 이란 단어와 가깝지만 나쁨 단어와는 거리가 있다 이런 정보\n",
    "\n",
    "Dense Representation 밀집 표현이라고도 부름\n",
    "\n",
    "```\n",
    "[0., 0., 0., 0., 0., 1.]\n",
    "```\n",
    "\n",
    "위가 희소 표현 방식이라면\n",
    "\n",
    "```\n",
    "[0.24, 0.113, 0.2541, 0.2566]\n",
    "```\n",
    "\n",
    "위가 밀집 표현 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "<img width=\"715\" alt=\"스크린샷 2021-12-02 오후 4 23 15\" src=\"https://user-images.githubusercontent.com/16532326/144376426-ba1fa8ec-14c9-4d1d-af50-e24b6e09f174.png\">\n",
    "\n",
    "\n",
    "[데모](http://w.elnn.kr/search/) 사이트에 내용을 보면 \n",
    "\n",
    "입력 데이터 벡터의 유사도를 이용하여 결과를 만들어 낼 수 있는 걸 알 수 있음\n",
    "\n",
    "- 단어의 의미를 벡터로 나타내는게 분산 표현\n",
    "- 단어의 유사도를 벡터로 나타내는게 워드 임베딩\n",
    "- 이를 저차원의 벡터로 변환한게  밀집 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산 표현(Distributed Representation)\n",
    "\n",
    "분포 가설을 이용\n",
    "\n",
    "```\n",
    "비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다\n",
    "```\n",
    "\n",
    "저차원의 벡터에 여러차원에 걸쳐 단어의 의미를 분산 시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW(Continuous Bag of Words)\n",
    "\n",
    "_현재 포인팅하고 있는 위치의 주변에 있는 단어들을 이용하여 현재 포인팅하는 위치의 단어를 예측_\n",
    "\n",
    "ex)\n",
    "\n",
    "This is my dog\n",
    "\n",
    "This <span style=\"color:blue\"> **is** </span> <span style=\"color:red\"> **??** </span> <span style=\"color:blue\"> **dog** </span>\n",
    "\n",
    "위 경우 처럼 `??` 라는 단어 주변에 있는 `is`, `dog` 를 이용하여 `??` 를 예측하는것\n",
    "\n",
    "용어로 예측할 가운데 단어를 center word, 주변 단어를 context word 라고 부름\n",
    "\n",
    "context word 의 길이를 window 라고 부르며 위의 경우 1\n",
    "\n",
    "![asdf](https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG)\n",
    "\n",
    "위 그림을 보면 중심 단어를 계속 이동시키며 학습을 하는데 이를 슬라이딩 윈도우 라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 주변단어를 입력, 중심단어를 출력으로 지정하게 됨\n",
    "\n",
    "따라서 중심 단어를 잘 예측하려면 중심 단어 one-hot-vector 필요\n",
    "\n",
    "`CBOW` 는 레이어가 하나인 얕은 신경망 구조와 활성함수가 없는 룩업 테이블 구조이기 때문에 프로젝션 레이어라고도 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![asdf](https://wikidocs.net/images/page/22660/word2vec_renew_3.PNG)\n",
    "\n",
    "Matrix: 5, Word vector: 7 (The, fat, cat, sat, on, the, mat)\n",
    "\n",
    "W 행렬은 기본 랜덤 값으로 정해져 있음\n",
    "\n",
    "여기다 x 값으로 cat 이 들어온다면\n",
    "\n",
    "```\n",
    "[0, 0, 1, 0, 0, 0, 0]\n",
    "```\n",
    "\n",
    "값이 채워진 걸과 W 행렬이 곱해질 것 이고, 사실상 결과 값으로 나올 V (cat) 값은 \n",
    "\n",
    "W 행렬의 x 값이 있었던 행의 값만 나오게 됨\n",
    "\n",
    "위 작업이 룩업 테이블 작업이고 이 데이터가 사실상 M 차원의 임베딩 데이터\n",
    "\n",
    "![asdf](https://wikidocs.net/images/page/22660/word2vec_renew_4.PNG)\n",
    "\n",
    "전 작업을 만약 윈도우 사이즈가 2 == n 라면 2 * n 번 각각 진행 하고,\n",
    "\n",
    "그의 벡터 평균을 계산함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![asdf](https://wikidocs.net/images/page/22660/word2vec_renew_5.PNG)\n",
    "\n",
    "전 결과로 벡터 평균 v 를 이용하여\n",
    "\n",
    "출력 층에도 있는 W' 에 값을 곱함\n",
    "\n",
    "그럼 다음 softmax 를 이용해 해당 벡터가 어느 위치에 있을 확률이 높은지를 계산함\n",
    "\n",
    "그럼다음 실제 y 값과 유사하게 만들기 위해 손실 항수로 cross-entropy 를 사용함 \n",
    "\n",
    "![asdf](https://wikidocs.net/images/page/22660/crossentrophy.PNG)\n",
    "\n",
    "쉽게 말해 -log 함수를 사용하여 모양이 대략\n",
    "\n",
    "<img width=\"238\" alt=\"스크린샷 2021-12-02 오후 5 36 50\" src=\"https://user-images.githubusercontent.com/16532326/144386627-43c16337-05d7-4add-a1e0-775fc1340ab9.png\">\n",
    "\n",
    "위와 같이 생기며, 출력 층의 one-hot-coding 된 y 벡터의 값이 있고, softmax(W' x v) 결과 간의 오차가 작아지게\n",
    "\n",
    "만들기 위해 역전파를 사용하여 수정을 해감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩 사용 방법은?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Embedding(16, 4, input_length=2)\n",
    "```\n",
    "\n",
    "16개의 단어가 입력으로 들어오지만 벡터 크기는 4로 고정하고, 입력은 매번 단어 2개씩만 들어간다 라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 긍/부정 판별\n",
    "\n",
    "[테스트 데이터](https://movie.naver.com/movie/bi/mi/point.naver?code=10016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    '크리스마스 최고의 영화',\n",
    "    '봐도봐도 질리지 않네',\n",
    "    '내인생 최고의 영화~!!',\n",
    "    '역사상 최고의 크리스마스 영화. 영화음악이 명곡이다.',\n",
    "    '언제 봐도 재미가 있는 영화여서 많이본다',\n",
    "    '유치찬란 허무맹랑 어의상실',\n",
    "    '으엑 이게뭐얔 무슨영화야 ㅋ',\n",
    "    '별로... 별로...',\n",
    "    '명절날 지겹게 봐서 1점',\n",
    "    '재미있어도 이제 그만 보고 싶음.. 너무 질려서'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_class = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'최고의': 1,\n",
       "  '영화': 2,\n",
       "  '크리스마스': 3,\n",
       "  '별로': 4,\n",
       "  '봐도봐도': 5,\n",
       "  '질리지': 6,\n",
       "  '않네': 7,\n",
       "  '내인생': 8,\n",
       "  '역사상': 9,\n",
       "  '영화음악이': 10,\n",
       "  '명곡이다': 11,\n",
       "  '언제': 12,\n",
       "  '봐도': 13,\n",
       "  '재미가': 14,\n",
       "  '있는': 15,\n",
       "  '영화여서': 16,\n",
       "  '많이본다': 17,\n",
       "  '유치찬란': 18,\n",
       "  '허무맹랑': 19,\n",
       "  '어의상실': 20,\n",
       "  '으엑': 21,\n",
       "  '이게뭐얔': 22,\n",
       "  '무슨영화야': 23,\n",
       "  'ㅋ': 24,\n",
       "  '명절날': 25,\n",
       "  '지겹게': 26,\n",
       "  '봐서': 27,\n",
       "  '1점': 28,\n",
       "  '재미있어도': 29,\n",
       "  '이제': 30,\n",
       "  '그만': 31,\n",
       "  '보고': 32,\n",
       "  '싶음': 33,\n",
       "  '너무': 34,\n",
       "  '질려서': 35},\n",
       " OrderedDict([('크리스마스', 2),\n",
       "              ('최고의', 3),\n",
       "              ('영화', 3),\n",
       "              ('봐도봐도', 1),\n",
       "              ('질리지', 1),\n",
       "              ('않네', 1),\n",
       "              ('내인생', 1),\n",
       "              ('역사상', 1),\n",
       "              ('영화음악이', 1),\n",
       "              ('명곡이다', 1),\n",
       "              ('언제', 1),\n",
       "              ('봐도', 1),\n",
       "              ('재미가', 1),\n",
       "              ('있는', 1),\n",
       "              ('영화여서', 1),\n",
       "              ('많이본다', 1),\n",
       "              ('유치찬란', 1),\n",
       "              ('허무맹랑', 1),\n",
       "              ('어의상실', 1),\n",
       "              ('으엑', 1),\n",
       "              ('이게뭐얔', 1),\n",
       "              ('무슨영화야', 1),\n",
       "              ('ㅋ', 1),\n",
       "              ('별로', 2),\n",
       "              ('명절날', 1),\n",
       "              ('지겹게', 1),\n",
       "              ('봐서', 1),\n",
       "              ('1점', 1),\n",
       "              ('재미있어도', 1),\n",
       "              ('이제', 1),\n",
       "              ('그만', 1),\n",
       "              ('보고', 1),\n",
       "              ('싶음', 1),\n",
       "              ('너무', 1),\n",
       "              ('질려서', 1)]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "token.word_index, token.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1, 2],\n",
       " [5, 6, 7],\n",
       " [8, 1, 2],\n",
       " [9, 1, 3, 2, 10, 11],\n",
       " [12, 13, 14, 15, 16, 17],\n",
       " [18, 19, 20],\n",
       " [21, 22, 23, 24],\n",
       " [4, 4],\n",
       " [25, 26, 27, 28],\n",
       " [29, 30, 31, 32, 33, 34, 35]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = token.texts_to_sequences(docs)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 벡터들의 길이가 서로 다 다르니 맞쳐주기 위해 패딩 기법사용하여\n",
    "\n",
    "길이들을 다 통일 시킴\n",
    "\n",
    "정해진 길이보다 길면 잘라냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  1,  2],\n",
       "       [ 0,  5,  6,  7],\n",
       "       [ 0,  8,  1,  2],\n",
       "       [ 3,  2, 10, 11],\n",
       "       [14, 15, 16, 17],\n",
       "       [ 0, 18, 19, 20],\n",
       "       [21, 22, 23, 24],\n",
       "       [ 0,  0,  4,  4],\n",
       "       [25, 26, 27, 28],\n",
       "       [32, 33, 34, 35]], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x = pad_sequences(x, 4)\n",
    "padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7fdf81f45588>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding(word_size, 8, input_length=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4개의 패딩을 만들었으므로 input_length = 4,\n",
    "\n",
    "임의로 8길이의 벡터를 출력으로 지정,\n",
    "\n",
    "word_size 는 총 입력 단어의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 8)              288       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(word_size, 8, input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 60ms/sample - loss: 0.6910 - accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 320us/sample - loss: 0.6885 - accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 373us/sample - loss: 0.6860 - accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 310us/sample - loss: 0.6834 - accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 0.6809 - accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 252us/sample - loss: 0.6784 - accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 0.6758 - accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 346us/sample - loss: 0.6733 - accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 330us/sample - loss: 0.6708 - accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 362us/sample - loss: 0.6682 - accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 295us/sample - loss: 0.6657 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 337us/sample - loss: 0.6631 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 0.6606 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 251us/sample - loss: 0.6580 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 267us/sample - loss: 0.6554 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 281us/sample - loss: 0.6528 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 0.6502 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 0.6476 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 350us/sample - loss: 0.6449 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 0.6423 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf821496a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_x, _class, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.6396 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padded_x, _class)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "_순환 신경망_\n",
    "\n",
    "순서데로 입력된 내용을 잠시 기억하여 나중에 얼마나 중요한 데이터인지 가중치를 줌\n",
    "\n",
    "같은 층에서 연산이 이루어져 순환이 되어지는 것처럼 보여 순환 신경망이라 부름\n",
    "\n",
    "이를 이용하여 `내일 날씨가 어때` 라는 문장에도 그냥 날씨 정보를 알려주는 것이 아닌 내일의 날씨를 알려주는 \n",
    "\n",
    "처리가 가능해짐\n",
    "\n",
    "# LSTM\n",
    "\n",
    "_Long Short Term Memory_\n",
    "\n",
    "`RNN` 에서 순환되어지는 데이터가 많아지게되면 기울기 연산이 많아지는 문제가 발생하여\n",
    "\n",
    "기억된 내용을 넘길지 버릴지를 판단하는 과정이 추가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words=1000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,\n",
       " 8982,\n",
       " 2246,\n",
       " [1,\n",
       "  2,\n",
       "  2,\n",
       "  8,\n",
       "  43,\n",
       "  10,\n",
       "  447,\n",
       "  5,\n",
       "  25,\n",
       "  207,\n",
       "  270,\n",
       "  5,\n",
       "  2,\n",
       "  111,\n",
       "  16,\n",
       "  369,\n",
       "  186,\n",
       "  90,\n",
       "  67,\n",
       "  7,\n",
       "  89,\n",
       "  5,\n",
       "  19,\n",
       "  102,\n",
       "  6,\n",
       "  19,\n",
       "  124,\n",
       "  15,\n",
       "  90,\n",
       "  67,\n",
       "  84,\n",
       "  22,\n",
       "  482,\n",
       "  26,\n",
       "  7,\n",
       "  48,\n",
       "  4,\n",
       "  49,\n",
       "  8,\n",
       "  864,\n",
       "  39,\n",
       "  209,\n",
       "  154,\n",
       "  6,\n",
       "  151,\n",
       "  6,\n",
       "  83,\n",
       "  11,\n",
       "  15,\n",
       "  22,\n",
       "  155,\n",
       "  11,\n",
       "  15,\n",
       "  7,\n",
       "  48,\n",
       "  9,\n",
       "  2,\n",
       "  2,\n",
       "  504,\n",
       "  6,\n",
       "  258,\n",
       "  6,\n",
       "  272,\n",
       "  11,\n",
       "  15,\n",
       "  22,\n",
       "  134,\n",
       "  44,\n",
       "  11,\n",
       "  15,\n",
       "  16,\n",
       "  8,\n",
       "  197,\n",
       "  2,\n",
       "  90,\n",
       "  67,\n",
       "  52,\n",
       "  29,\n",
       "  209,\n",
       "  30,\n",
       "  32,\n",
       "  132,\n",
       "  6,\n",
       "  109,\n",
       "  15,\n",
       "  17,\n",
       "  12],\n",
       " 87)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.max(Y_train) + 1\n",
    "category, len(X_train), len(X_test), X_train[0], len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```X_train[0]```\n",
    "\n",
    "의 경우, 단어 출현 빈도수에 따라 인덱스 번호가 매겨져 변환된 데이터로 이루어진 문장임\n",
    "\n",
    "즉, 전처리가 이미 일부 진행된 데이터\n",
    "\n",
    "이 중, 잘 사용되어지지 않는 데이터가 있을 수 있음\n",
    "\n",
    "그 경우 순위권에서 많이 밀려난 값을 가질텐데 그 threshold 값으로 ```num_word=1000``` 값을 주었으며,\n",
    "\n",
    "따라서 1000 순위 까지의 단어만 나오게 될 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         1,   2,   2,   8,  43,  10, 447,   5,  25, 207, 270,   5,   2,\n",
       "       111,  16, 369, 186,  90,  67,   7,  89,   5,  19, 102,   6,  19,\n",
       "       124,  15,  90,  67,  84,  22, 482,  26,   7,  48,   4,  49,   8,\n",
       "       864,  39, 209, 154,   6, 151,   6,  83,  11,  15,  22, 155,  11,\n",
       "        15,   7,  48,   9,   2,   2, 504,   6, 258,   6, 272,  11,  15,\n",
       "        22, 134,  44,  11,  15,  16,   8, 197,   2,  90,  67,  52,  29,\n",
       "       209,  30,  32, 132,   6, 109,  15,  17,  12], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pad_sequences(X_train, maxlen=100)\n",
    "x_test = pad_sequences(X_test, maxlen=100)\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 데이터 별로 길이값이 다르므로 맞추어 주기 위해 ```pad_sequences maxlen=100``` 으로 패딩하여 길이 맞춰줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "Y_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`one-hot encoding` 으로 카테고리 값 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         100000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                4646      \n",
      "=================================================================\n",
      "Total params: 185,046\n",
      "Trainable params: 185,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(1000, 100))\n",
    "model.add(LSTM(100, activation='tanh'))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tanh` 는 `sigmoid` 의 0 ~ 1 보다 범위가 큰 S 자 형태의 -1 ~ 1 범위를 가짐\n",
    "\n",
    "`sigomid` 는 미분하면 값이 0 ~ 0.25 까지의 값을 가지기 때문에 여러 층을 가지는 \n",
    "\n",
    "머신러닝 구조에선 값이 0으로 수렴하는 문제가 생길 수 있기 때문에 얕은 머신러닝일때 쓰고\n",
    "\n",
    "보다 깊은 머신러닝일땐 미분하여도 0 ~ 1 까지 값을 가지는 `tanh` 가 유리\n",
    "\n",
    "하지만 둘다 Gradient Vanishing 문제가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Vanishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1미만의 값을 곱하기 연산을 할 수록 결국 0에 가깝게 수렴하게됨\n",
    "\n",
    "위 머신러닝에서도 미분을 하게되어지면 x 가 0에 가까워야 1에 가까운 값을 가지게 되지만\n",
    "\n",
    "결국 여러번 연산을 거치게 되면 0에 가까워 질 것이란 것\n",
    "\n",
    "반대의 문제로 기울기 값이 너무 커지면 너무 큰 값을 가지게 되는 문제로 `Gradient Exploding` 가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Embedding``` 학습에서 사용될 단어 갯수, 각 데이터당 사용된 단어 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 16s 2ms/sample - loss: 2.5627 - accuracy: 0.3712 - val_loss: 2.1419 - val_accuracy: 0.4880\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 2.0581 - accuracy: 0.4931 - val_loss: 2.0546 - val_accuracy: 0.4978\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 2.0016 - accuracy: 0.5077 - val_loss: 1.9960 - val_accuracy: 0.5134\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 1.9177 - accuracy: 0.5257 - val_loss: 1.9478 - val_accuracy: 0.5307\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.7971 - accuracy: 0.5618 - val_loss: 1.7588 - val_accuracy: 0.5766\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 1.5813 - accuracy: 0.6103 - val_loss: 1.5956 - val_accuracy: 0.5922\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 1.4749 - accuracy: 0.6225 - val_loss: 1.5183 - val_accuracy: 0.6247\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.3970 - accuracy: 0.6461 - val_loss: 1.4645 - val_accuracy: 0.6349\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.3471 - accuracy: 0.6559 - val_loss: 1.4468 - val_accuracy: 0.6362\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 1.2760 - accuracy: 0.6797 - val_loss: 1.4262 - val_accuracy: 0.6345\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.2285 - accuracy: 0.6902 - val_loss: 1.3492 - val_accuracy: 0.6585\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.1617 - accuracy: 0.7056 - val_loss: 1.3097 - val_accuracy: 0.6683\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.1105 - accuracy: 0.7188 - val_loss: 1.3023 - val_accuracy: 0.6638\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 1.0664 - accuracy: 0.7320 - val_loss: 1.2505 - val_accuracy: 0.6794\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 1.0143 - accuracy: 0.7423 - val_loss: 1.2554 - val_accuracy: 0.6883\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 15s 2ms/sample - loss: 0.9701 - accuracy: 0.7562 - val_loss: 1.2222 - val_accuracy: 0.6955\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 0.9506 - accuracy: 0.7594 - val_loss: 1.2189 - val_accuracy: 0.7070\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 14s 2ms/sample - loss: 0.9039 - accuracy: 0.7739 - val_loss: 1.2009 - val_accuracy: 0.7075\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 0.8696 - accuracy: 0.7829 - val_loss: 1.1756 - val_accuracy: 0.7012\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 13s 1ms/sample - loss: 0.8366 - accuracy: 0.7939 - val_loss: 1.1931 - val_accuracy: 0.7061\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=100, epochs=20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = np.arange(len(y_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='Trainset_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
